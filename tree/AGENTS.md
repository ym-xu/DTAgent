# documents

the documents we use are form Mineru, stores at /data/users/yiming/dtagent/MinerU_MMLB

under the MinerU_MMLB, every PDF has a own directory with same name cut '.pdf', in the directory,we have content_list.json and layout.json and image/ and full.md

in current content_list, only the titles(generated by mineru) has "text_level", and all of their "text_level" is 1, in layout.json, we can find the images' bbox

# content_list enhance:
```
input :

[
    {
        "type": "text",
        "text": "UndergraduateProspectus",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "image",
        "img_path": "images/ca5dfe4537f20eab2806e7f379389553f48f18730bf480f8f4ffc43df30a11ec.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "CONTENTS",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "2 TOP 10 REASONS WHY NTU SMART CAMPUS IS FOR YOU 4 BE AMONG THE TOP RANKED 6 NURTURING TALENT FOR THE GOOD 8 A TRANSFORMATIVE LEARNING",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "10 PREMIER SCHOLARS PROGRAMMES",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "table",
        "img_path": "images/f0f54084622cac60b63859683860e54002612b7c339227eeca17182f824a7ea0.jpg",
        "table_caption": [
            "APPLICATION PERIOD AND FEE"
        ],
        "table_footnote": [],
        "table_body": "<table><tr> ... </tr></table>",
        "page_idx": 24
    },
    {
        "type": "equation",
        "text": "\n$$\nI_{l} = \\left|\\sum_{i}A_{h,i}\\odot \\frac{\\partial\\mathcal{L}(x)}{\\partial A_{h,i}}\\right|. \\tag{1}\n$$\n",
        "text_format": "latex",
        "page_idx": 1
    },
    ...
]

enhance and output:
[
    {
        "type": "text",
        "text": "UndergraduateProspectus",
        "node_level": 1, # [dev] text_level change name to node_level
        "page_idx": 0,
        "node_idx": 0 # [dev] add node_idx from i to i++
    },
    {
        "type": "image",
        "img_path": "images/....jpg",
        "image_caption": [],
        "image_footnote": [],
        "text": # OCR the image extract text
        "outline": [] # add from layout.json
        "description": # qwen2.5vl
        "node_level": -1 add node_level, can be -1, to be add a true num
        "page_idx": 1
        "node_idx": 0 # [dev] add node_idx from i to i++
    },
    ...
    {
        "type": "table",
        "img_path": "images/....jpg",
        "table_caption": [
            "APPLICATION PERIOD AND FEE"
        ],
        "table_footnote": [],
        "table_body": "<table><tr> ... </tr></table>",
        "node_level": -1 # add node_level, can be -1, to be add a true num
        "page_idx": 24,
        "outline": [] # add from layout.json
        "node_idx": 0 # [dev] add node_idx from i to i++
    },
    {
        "type": "equation",
        "text": "\n$$\nI_{l} = \\left|\\sum_{i}A_{h,i}\\odot \\frac{\\partial\\mathcal{L}(x)}{\\partial A_{h,i}}\\right|. \\tag{1}\n$$\n",
        "text_format": "latex",
        "page_idx": 1,
        "node_level": -1 add node_level, can be -1, to be add a true num
        "node_idx": 0
    },
]
```

# Design Multimodal DocTree:

```
input: 
    enhanced content_list:
        [
            {
                "type": text
                "text":
                "node_level":
                "page_idx":
                "node_idx":
            },
            {
                "type": image
                "img_path":
                "image_caption":
                "image_footnote":
                "text":
                "outline"
                "description"
                "node_level":
                "page_idx":
                "node_idx":
            },
            {
                "type": table
                "img_path": "./..."
                "table_caption":  
                "table_footnote":
                "table_body":
                "node_level":
                "page_idx":
                "outline":
                "node_idx":
            }
            ...
        ]
output:
    MM DocTree
```

## The Node design:

```
text:
{
    'type': text
    'node_id':
    'page_idx':
    'title':
    'text':
}
image:
{
    'type': image
    'node_id':
    'page_idx':
    'caption':
    'image_path':
    'description':
}
table:
{
    'type': table
    'node_id':
    'page_idx':
    'caption':
    'data':
}
equation:
{
    'type': equation
    'node_id':
    'page_idx':
    'text':
}
toc:
{
    'type': toc
    'node_id':
    'page_idx':
    'data':
}
```

# MMDocTree build logic

## 1. check toc

- if True
    - extract toc node
        - create table node
        - delete duplicate nodes

---

## Progress Status (2025-09-09)

What’s implemented now
- Adapter (`tree/adapter.py`):
  - Adds `node_idx` (0..n-1) for all items.
  - Renames `text_level` → `node_level` when present; defaults `node_level=-1` when missing (includes non-title text, image, table, equation, code).
  - Enriches `image`/`table` with `outline` (bbox) by scanning `layout.json` (`pdf_info.*.image_path` + `bbox`).
  - Ensures `image` items always have `text` and `description` keys (empty if OCR/LLM not used).
  - Batch and single-file processing; directory mode supports `--in-place` and `--suffix`.
- Utils (`tree/utils.py`):
  - `try_ocr_image(path)` optional OCR via pytesseract (not called by default).
  - `describe_image_with_llm(path, prompt=None, **kwargs)` placeholder (not called by default).
- README (`tree/README.md`):
  - Documents adapter behavior, CLI usage, and input/output examples (includes equation before/after).

CLI behavior
- Directory mode:
  - Default (keep originals): `python -m tree.adapter --in-dir DIR` → writes alongside as `content_list.adapted.json` (customize with `--suffix`).
  - Overwrite originals: `python -m tree.adapter --in-dir DIR --in-place`.
- Single-file mode:
  - Default: `python -m tree.adapter --in-file FILE --layout-file LAYOUT` → writes `*.adapted.json` (or `--out` / `--suffix`).
  - Overwrite: add `--in-place`.

Agreed but NOT implemented yet
- Flat DocTree builder (Document root with linear children) and serialization to `doctree.json`.
- Optional extraction of `equation_id` from LaTeX `\tag{...}`.

Update (2025-09-09)
- Implemented: `table_text` extraction from `table_body` as Markdown when possible (falls back to plain text).
- Dropped: caption normalization; keep original caption-related fields as-is.

Update (2025-09-11)
- Added page-level refinement APIs (no CLI):
  - `page_payload.py`: build compact payload for a page (elements with node_id/type/snippet/outline).
  - `page_plan.py`: validate and normalize model outputs (plan/jsonlist).
  - `refine_apply.py`: pure functions to apply plan or nodes to doctree and reindex.
  - `llm_providers.py`: provider interfaces (Qwen/GPT/Mock) for future integration; no network code included.
  - `prompts.py`: strict JSON-only prompt templates for plan/jsonlist.
- Demo notebook `tree/page_refine_demo.ipynb` to test a chosen page interactively.

Added Flat DocTree builder
- New CLI: `python -m tree.builder --in-dir DIR` or `--in-file FILE`
- Output: `doctree.json` per PDF directory (no in-place overwrite of MinerU files)
- doc_id = directory name; indices enabled by default (by_page, by_type, id_to_idx)

Out of scope for now (later with heuristics/LLM)
- Title/section detection, TOC extraction, list nesting via stack, figure/table caption pairing, code block refinement.

Assumptions / data constraints
- MinerU content_list already filtered for headers/footers; reading order is single-column; documents are English; tables include HTML and image; no font/size metadata.

Next steps (proposed)
- Implement caption normalization and `table_text` extraction in adapter.
- Optionally add a minimal `build-tree` CLI to emit a flat `doctree.json` for downstream use.
    - find ignored title
        - find nodes by page_idx, check text
- else
    - LLM(titles)

## 2. title disambiguation
- image title 
