# AGENTS.md â€” Multimodal DocTree Agent System

## ğŸŒ² 1. System Overview
Our goal is to perform **explainable multimodal long-document QA** over structured DocTrees.  
The pipeline consists of four major modules:

| Stage | Module | Purpose |
|-------|---------|----------|
| M0 | Adapter + Enhancer + Builder | Parse PDF â†’ Enhanced content â†’ Hierarchical DocTree |
| M1 | Indexer | Build node-level embeddings and summaries |
| M2 | Agent System (Plannerâ€“Observerâ€“Reasoner) | Navigate tree, gather evidence, reason to answer |
| M3 | Evaluation | Measure retrieval & reasoning performance vs RAG baseline |

---

## ğŸ§© 2. Core Agent Architecture
The agent operates through an **iterative navigationâ€“observationâ€“reasoning loop**.

### 2.1 Planner (Navigation)
- **Goal:** Select which DocTree nodes (sections/pages) to inspect next.  
- **Inputs:**  
  - User question (Q)  
  - Node summaries + embeddings  
  - Structural context (parent/child hierarchy)  
- **Outputs:**  
  - A ranked plan of candidate nodes (e.g., `HIT_SUMMARY` and `HEADINGS_TOPK`)  
  - Optional action directives: `MOVE_TO(section=X)`, `EXPAND_CHILDREN`, etc.  
- **Prompt context:** Focused summaries + structure + hints.

### 2.2 Observer (Perception)
- **Goal:** Retrieve multimodal evidence from nodes chosen by the Planner.  
- **Subagents:**  
  - `TextObserver`: extracts paragraphs/lists/equations.  
  - `ImageObserver`: calls VLM for chart/table interpretation.  
  - `TableObserver`: reads and converts tables to text.  
- **Output:** structured observations `{node_id, modality, payload}`.

### 2.3 Reasoner (Inference)
- **Goal:** Synthesize all evidence, generate or verify the final answer.  
- **Input:** question + observed contents.  
- **Output:**  
  - Final JSON: `{answer, confidence, support_nodes}`  
  - If uncertainty high â†’ emit `REPLAN` signal.

### 2.4 Router (Optional)
- **When:** complex question requiring decomposition.  
- **Action:** produce sub-questions â†’ recursively call planner/observer/reasoner.  
- **Example:** â€œList top-3 findings and explain their data sources.â€

### 2.5 Memory (Cache)
- Caches node summaries, embedding hits, and previous observations.
- Prevents re-querying the same sections and saves reasoning trace for debugging.

---

## âš™ï¸ 3. Data Flow Summary
```text
Question â†’ Planner â†’ Candidate nodes â†’ Observer â†’ Evidence â†’ Reasoner â†’ Answer
                  â†‘                                               â†“
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[REPLAN if insufficient info]â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§  4. Context Engineering Principles
	1.	Question Rewriting: Add domain hints (e.g., â€œfigure countâ€, â€œchart titleâ€).
	2.	Structured Prompt Windows: Combine heading, summary, and neighbor nodes in one coherent context block.
	3.	Role Conditioning:
	â€¢	Planner prompt uses â€œYou are a document navigatorâ€
	â€¢	Reasoner prompt uses â€œYou are an analyst reasoning over structured evidenceâ€
	4.	Summaries-as-Index:
	â€¢	Each node stores a summary (â‰ˆ100 tokens) used in HEADINGS_TOPK.
	â€¢	Enables cheap semantic navigation before full-text access.

## ğŸ—‚ï¸ 5. Directory Structure
```
project_root/
â”‚
â”œâ”€â”€ data/                           # å­˜å‚¨ä¸­é—´ä¸æœ€ç»ˆæ•°æ®æ–‡ä»¶            
â”‚   â”œâ”€â”€ dataset_n/  
|   |   â”œâ”€â”€ doc_id_1/           
â”‚   â”‚   â”‚   â”œâ”€â”€ full.pdf
â”‚   â”‚   â”‚   â”œâ”€â”€ layout.json
â”‚   â”‚   â”‚   â”œâ”€â”€ content_list.json
â”‚   â”‚   â”‚   â”œâ”€â”€ content_list.adapted.json # M1
â”‚   â”‚   â”‚   â”œâ”€â”€ content_list.enhanced.json # M1
â”‚   â”‚   â”‚   â”œâ”€â”€ doctree.mm.json # M1
â”‚   â”‚   â”‚   â””â”€â”€ index/          # M2
â”‚   â”‚   â”‚       â”œâ”€â”€ summary.json
â”‚   â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚   
â”‚   â”‚   â”œâ”€â”€ doc_id_n/
â”‚   â”‚   â”‚   â”œâ”€â”€ full.pdf
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ qa/                     # QAä»»åŠ¡æ–‡ä»¶ä¸ç»“æœ
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ adapter/                    # M0: PDFâ†’content_list
â”‚   â”‚   â”œâ”€â”€ adapter_v2.py
â”‚   â”‚   â””â”€â”€ ...
â”‚
â”‚   â”œâ”€â”€ enhancer/                   # M1: å›¾åƒå¢å¼º+æ ‡é¢˜ä¿®å¤
â”‚   â”‚   â”œâ”€â”€ enhancer_2.py
â”‚   â”‚   â”œâ”€â”€ merge_subfigures.py     # åˆå¹¶è¯¯åˆ†å‰²å­å›¾
â”‚   â”‚   â”œâ”€â”€ caption_guard.py        # å›¾é¢˜/ç« èŠ‚æ ‡é¢˜åŒºåˆ†
â”‚   â”‚   â”œâ”€â”€ heading_cleanup.py      # é¡µçœ‰é¡µè„šå»é‡
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚
â”‚   â”œâ”€â”€ builder/                    # M1+: æ ‘ç»“æ„æ„å»º
â”‚   â”‚   â”œâ”€â”€ tree_builder.py
â”‚   â”‚   â”œâ”€â”€ tree_utils.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚
â”‚   â”œâ”€â”€ index/                      # M2: èŠ‚ç‚¹æ‘˜è¦ + å‘é‡ç´¢å¼•
â”‚   â”‚   â”œâ”€â”€ node_summarizer.py      # èŠ‚ç‚¹æ‘˜è¦ç”Ÿæˆï¼ˆLLMï¼‰
â”‚   â”‚   â”œâ”€â”€ semantic_index.py       # å‘é‡åŒ–ä¸ç´¢å¼•
â”‚   â”‚   â”œâ”€â”€ embed_models.py         # ç»Ÿä¸€embeddingæ¥å£
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚
â”‚   â”œâ”€â”€ agents/                     # M3: æ ¸å¿ƒå¤šæ¨¡æ€Agentç³»ç»Ÿ
â”‚   â”‚   â”œâ”€â”€ planner.py              # è§„åˆ’å¯¼èˆªï¼ˆç»“æ„+è¯­ä¹‰æ£€ç´¢ï¼‰
â”‚   â”‚   â”œâ”€â”€ observer.py             # å¤šæ¨¡æ€è§‚æµ‹
â”‚   â”‚   â”œâ”€â”€ reasoner.py             # æ¨ç†ä¸ç­”æ¡ˆæ•´åˆ
â”‚   â”‚   â”œâ”€â”€ router.py               # å­é—®é¢˜æ‹†åˆ†ä¸è°ƒåº¦
â”‚   â”‚   â”œâ”€â”€ memory.py               # ç¼“å­˜ä¸ä¸Šä¸‹æ–‡è®°å¿†
â”‚   â”‚   â”œâ”€â”€ agent_loop.py           # ä¸»å¾ªç¯ (plannerâ†’observerâ†’reasoner)
â”‚   â”‚   â””â”€â”€ agent_config.yaml       # Agentç³»ç»Ÿé…ç½®
â”‚
â”‚   â”œâ”€â”€ eval/                       # M4: å®éªŒè¯„æµ‹
â”‚   â”‚   â”œâ”€â”€ metrics.py              # hit@k, F1, exact match
â”‚   â”‚   â”œâ”€â”€ ablation_runner.py      # æ¨¡å—æ¶ˆèæµ‹è¯•
â”‚   â”‚   â”œâ”€â”€ eval_baselines.py       # RAG/å…¨æ–‡æ¨¡å‹å¯¹æ¯”
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚
â”‚   â”œâ”€â”€ rag_baseline/               # M4: RAGåŸºçº¿å®éªŒ
â”‚   â”‚   â”œâ”€â”€ rag_retrieval.py
â”‚   â”‚   â”œâ”€â”€ rag_eval.py
â”‚   â”‚   â”œâ”€â”€ rag_index.py
â”‚   â”‚   â””â”€â”€ rag_config.yaml
â”‚
â”‚   â”œâ”€â”€ utils/                      # é€šç”¨å‡½æ•°ä¸å·¥å…·
â”‚   â”‚   â”œâ”€â”€ llm_clients.py          # GPT/Qwenè°ƒç”¨ç»Ÿä¸€æ¥å£
â”‚   â”‚   â”œâ”€â”€ layout_utils.py         # bboxä¸å‡ ä½•å·¥å…·
â”‚   â”‚   â”œâ”€â”€ logging_utils.py        # æ—¥å¿—ç³»ç»Ÿ
â”‚   â”‚   â”œâ”€â”€ tree_nav.py             # æ ‘ç»“æ„å¯¼èˆª/æœç´¢
â”‚   â”‚   â”œâ”€â”€ json_io.py              # JSON IOä¸ç¼“å­˜
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ run_agents.py               # ä¸»Agentå®éªŒå…¥å£
â”‚   â”œâ”€â”€ run_rag.py                  # RAGåŸºçº¿å®éªŒå…¥å£
â”‚   â”œâ”€â”€ config.yaml                 # å®éªŒé…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ analysis.ipynb              # ç»“æœå¯è§†åŒ–ä¸åˆ†æ
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ predictions/
â”‚   â”œâ”€â”€ traces/                     # reasoningè·¯å¾„ä¸AgentçŠ¶æ€
â”‚   â””â”€â”€ metrics_summary.json
â”‚
â””â”€â”€ AGENTS.md                       # Codexåä½œæŒ‡å—
```

## ğŸ§ª 6. Example Interaction
Q: â€œHow many line plots are there in the report?â€

Planner:
	â€¢	Retrieve nodes with summary hints containing figure, plot, chart.
	â€¢	Choose pages labeled as containing â€œline chartsâ€.

Observer:
	â€¢	Collect all image nodes with metadata "kind": "statistical".
	â€¢	Use VLM to classify chart type.

Reasoner:
	â€¢	Count charts where type = â€œlineâ€
	â€¢	Return: {answer: 7, support_nodes: [img_3, img_17, img_45]}

## ğŸ§± 7. Development Phases
| Phase | Goal | Key Output |
|-------|---------|----------|
| M0 | PDF â†’ Adapted JSON | content_list.adapted.json |
| M1 | Enhance + DocTree | doctree.mm.json |
| M2 | Summaries + Embedding | index.pkl, summary.json |
| M3 | Agents System | answers.json, reasoning traces |
| M4 | Evaluation | metrics + ablation results |

## ğŸ§© 8. References
	â€¢	Anthropic (2025). Effective Context Engineering for AI Agents.

## ğŸ§­ 9. Notes
	â€¢	Always start from DocTree (.mm.json).
	â€¢	Never feed full document text to the Planner directly.
	â€¢	Maintain consistent JSON I/O between modules.

---

## ğŸ§± 10. Index Features (Design + Examples)

This section defines the complete feature schema for agent-controlled retrieval over DocTrees. It introduces dense/sparse views, hierarchical section features, filters/facets, affordances, and explicit graph edges, with concrete JSON examples.

### 10.1 Goals
- Navigable: Sections act as hierarchical routers (coarse â†’ fine).
- Precise: Symbolic fields (labels, schema, units) are queryable via sparse/BM25F.
- Explainable: All results map to nodes and edges; paths can be replayed.
- Performant: Separate ANN per view; BM25F per role. Supports fusion and rerank.

### 10.2 Artifacts and Files
Under `indexes/<doc_id>/`:

```
summary.json
dense_coarse.jsonl       # sections/images/tables (incl. variants for sections)
dense_leaf.jsonl         # leaves (paragraph/list/caption/equation)
sparse_coarse.jsonl      # BM25F docs for coarse nodes
sparse_leaf.jsonl        # BM25F docs for leaf nodes
graph_edges.jsonl        # parent/child/same_page/ref/prev_next/has_col...
id_maps.json             # "Figure 1"â†’img_id, "Table 2"â†’tab_id, etc.
coarse.faiss / coarse.vectors.npy + coarse.meta.json
leaf.faiss   / leaf.vectors.npy   + leaf.meta.json
bm25_coarse/  bm25_leaf/
```

Notes:
- For sections, multiple dense variants are emitted (see 10.3.1) either as separate records with `variant` field and `node_id` suffix (e.g., `sec_12#h/#g/#c/#p`) or unified then split during index build.

### 10.3 Schemas

#### 10.3.1 Dense (coarse) â€” Sections with variants
Variants per section optimize hierarchical navigation and intent routing:
- `heading_text` (`variant: "heading"`): only the section title, for global coarse recall.
- `local_gist` (`variant: "gist"`): 2â€“3 sentence MMR summary from the sectionâ€™s own text.
- `child_surface` (`variant: "child"`): synthesized from child captions, table schemas, child headings.
- `path_text` (`variant: "path"`): concatenated ancestor heading path.

Example (one variant shown):

```json
{
  "node_id": "sec_12#c",
  "variant": "child",
  "role": "section",
  "dense_text": "Figure 3 accuracy over time; Table 2 hyper-parameters. Accuracy (%) and Latency (ms) discussed.",
  "title": "2.3 Training",
  "summary": "Optimization details and empirical settings.",
  "filters": {
    "page_idx": 4,
    "level": 2,
    "parent_section": "sec_6",
    "parent_title": "2 Method",
    "page_span": [3, 7],
    "chart_types": ["statistical"],
    "units_set": ["%", "ms"]
  },
  "affordances": {
    "supports_ROUTE_TO_image": true,
    "supports_ROUTE_TO_table": true,
    "has_numbers": true,
    "supports_COMPARE": true,
    "supports_LOOKUP": true,
    "supports_TREND": true
  },
  "subtree_sketch": {
    "keywords_topk": ["accuracy", "%", "latency", "ms", "hyper-parameters"],
    "representatives": {
      "top_image": "img_31",
      "top_table": "tab_21",
      "top_paragraph": "t_230#c0"
    }
  }
}
```

Other variants of the same section share `role/filters/affordances` but differ in `node_id/variant/dense_text`.

#### 10.3.2 Dense (coarse) â€” Images/Tables

```json
{
  "node_id": "img_14",
  "role": "image",
  "dense_text": "Line chart comparing accuracy across models over time.",
  "title": "Figure 3: Accuracy over time",
  "summary": "A statistical line chart showing models' accuracy changes.",
  "filters": {
    "page_idx": 5,
    "parent_section": "sec_12",
    "parent_title": "2.3 Training",
    "chart_type": "statistical",
    "label": "Figure 3",
    "figure_no": "3",
    "units_set": ["%"]
  },
  "affordances": {
    "has_numbers": true,
    "supports_COMPARE": true,
    "supports_TREND": true,
    "supports_LOOKUP": false
  }
}
```

```json
{
  "node_id": "tab_21",
  "role": "table",
  "dense_text": "Hyper-parameters with accuracy (%) and latency (ms) per configuration.",
  "title": "Table 2: Hyper-parameters and metrics",
  "summary": "Lists accuracy and latency per setting.",
  "filters": {
    "page_idx": 6,
    "parent_section": "sec_12",
    "label": "Table 2",
    "table_no": "2",
    "units_set": ["%", "ms"]
  },
  "affordances": {
    "has_numbers": true,
    "supports_COMPARE": true,
    "supports_LOOKUP": true,
    "supports_TREND": false
  }
}
```

#### 10.3.3 Dense (leaf) â€” Paragraph/List/Caption/Equation

```json
{
  "node_id": "t_230#c0",
  "orig_node_id": "t_230",
  "role": "paragraph",
  "dense_text": "We report accuracy (%) and latency (ms) for each model.",
  "raw_text": "We report accuracy (%) and latency (ms)...",
  "filters": { "page_idx": 5, "parent_section": "sec_12", "units_set": ["%", "ms"] },
  "refs": [ { "type": "ref", "label": "Figure 3", "target": "img_14" } ]
}
```

#### 10.3.4 Sparse (coarse/leaf) â€” BM25F Docs
Fields with per-field weights enable precise matches on labels/schema/aliases.

```json
{
  "id": "sec_12",
  "role": "section",
  "heading": "2.3 Training",
  "headings_path": "2 Method > 2.3 Training",
  "child_labels": "Figure 3; Table 2",
  "child_table_schema": "Accuracy (%); Latency (ms)",
  "caption_bag": "line chart accuracy over time; hyper-parameters table",
  "aliases": "acc accuracy pct percent ms millisecond",
  "body": "Optimization details and empirical settings.",
  "filters": { "level": 2, "page_span": [3, 7] }
}
```

```json
{
  "id": "tab_21",
  "role": "table",
  "title": "Table 2: Hyper-parameters and metrics",
  "caption": "Accuracy (%) and latency (ms) per configuration.",
  "table_schema": "Accuracy (%); Latency (ms)",
  "aliases": "acc accuracy pct percent ms millisecond",
  "labels": "Table 2",
  "body": "Lists metrics per setting.",
  "filters": { "page_idx": 6, "parent_section": "sec_12" }
}
```

#### 10.3.5 Graph Edges and ID Maps

```json
{ "src": "sec_12",  "dst": "img_14", "type": "child" }
{ "src": "sec_12",  "dst": "tab_21", "type": "child" }
{ "src": "t_230#c0", "dst": "img_14", "type": "ref", "label": "Figure 3" }
{ "src": "P5",      "dst": "img_14", "type": "same_page" }
{ "src": "tab_21",  "dst": "tab_21:col:Accuracy(%)", "type": "has_col", "unit": "%" }
```

```json
{
  "label2id": { "Figure 3": "img_14", "Table 2": "tab_21" },
  "figure": { "3": "img_14" },
  "table": { "2": "tab_21" }
}
```

### 10.4 Retrieval Strategy (Planner-Ready)
- Intent detection â†’ choose roles/views/filters:
  - Find table/column/unit: prefer `section.child_surface` + `table.schema` hits; `supports_LOOKUP`â†‘.
  - Find figure/trend: prefer `image.chart_type=statistical`; `supports_TREND`â†‘; caption/labels hits.
  - Concept/definition: prefer `section.heading/path + local_gist`.
- Dual-channel recall and fusion:
  - Dense ANN (per variant) and BM25F in parallel, each Top-K.
  - Fusion score (default): `0.45*dense + 0.35*bm25f + 0.10*tree_prior + 0.10*intent_bonus`.
  - Tree prior: same_section, page_distance, depth_prior.
- Tree expansion:
  - Hit section â†’ representatives (top_image/table/paragraph), childrenâ‰¤2, siblingsâ‰¤2, same_pageâ‰¤8.
  - Hit image/table â†’ add caption, parent_section, referring paragraphs via `ref` edges.
- Lightweight rerank features:
  - `is_title_hit, is_path_hit, is_label_hit, schema_hit, alias_hit, unit_match, page_dist, same_section, supports_* âˆ§ intent`.

### 10.5 Observer Packaging
- Image/Table: caption + schema_brief + optional cells; always include anchors `page_idx/bbox/cell`.
- Section: very short `summary_gist`.
- Paragraph: when used as evidence, include `raw_text`.

### 10.6 Defaults
- MMR: section k=3 (long k=6), image/table k=3, leaf k=1â€“2, Î»â‰ˆ0.72.
- Recall: K_dense=200, K_sparse=200 â†’ rerank to 30â€“50.
- Expansion: parent=1, siblingsâ‰¤2, childrenâ‰¤2, same_pageâ‰¤8.
- ANN (reference): HNSW M=32, efC=200, efS=64.

### 10.7 Rationale
- Separate semantic vs symbolic channels reduces noise and improves explainability.
- Section variants align with human navigation: heading/path (global) â†’ child_surface/gist (local).
- Graph edges and affordances support controllable exploration and precise Observer ops.

dense :
  coarse.faiss (section æ‘˜è¦)
  leaf.faiss ï¼ˆleaf æ‘˜è¦ï¼‰
  leaf_raw.faissï¼ˆleaf åŸæ–‡ï¼‰

sparse:
  bm25_coarse/
  bm25_leaf/

JSON/JSONL
  - summary.json
  - dense_coarse.jsonlï¼šsection å¤šè§†å›¾ï¼ˆheading/gist/child/pathï¼‰+ image/table çš„ dense
  - dense_leaf.jsonlï¼šå¶å­æ‘˜è¦ï¼ˆå« raw_textï¼Œä»…æ‘˜è¦ç”¨äºå‘é‡ï¼‰
  - sparse_coarse.jsonlï¼šcoarse ç¨€ç–ï¼ˆå« title/caption/table_schema/labels/aliases/bodyï¼‰
  - sparse_leaf.jsonlï¼šleaf ç¨€ç–ï¼ˆbody=raw_textï¼‰
  - graph_edges.jsonlï¼šparent/child/same_page/prev_next/ref/has_col
  - id_maps.jsonï¼šå›¾è¡¨å·æ˜ å°„