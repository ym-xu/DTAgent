{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa90ce27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ymxu/Workspace/MuDocU/DTAgent\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/ymxu/Workspace/MuDocU/DTAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f297985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "ALLOWED_STRATEGY = {\"direct_label\",\"direct_page\",\"sparse\",\"dense\",\"hybrid\",\"leaf\",\"heading\"}\n",
    "ALLOWED_ROLES = {\"section\",\"image\",\"table\",\"paragraph\",\"caption\"}\n",
    "ALLOWED_EXPAND = {\"child\",\"same_page\",\"parent\",\"ref\"}\n",
    "\n",
    "POLICY_SYS = (\n",
    "\"你是检索策略规划器。仅返回严格 JSON。\"\n",
    "\"根据问题选择一种策略，并尽量填充直达选择器（如有）。\"\n",
    "\"JSON 结构：\"\n",
    "\"{\"\n",
    "\"\\\"strategy\\\":\\\"direct_label|direct_page|sparse|dense|hybrid|leaf|heading\\\",\"\n",
    "\"\\\"roles\\\":[\\\"section|image|table|paragraph|caption\\\"],\"\n",
    "\"\\\"selectors\\\":{\\\"label\\\":\\\"\\\",\\\"figure_no\\\":\\\"\\\",\\\"table_no\\\":\\\"\\\",\\\"page\\\":0},\"\n",
    "\"\\\"queries\\\":{\\\"dense\\\":\\\"\\\",\\\"sparse\\\":\\\"\\\"},\"\n",
    "\"\\\"need_leaf\\\":true|false,\"\n",
    "\"\\\"expand\\\":{\\\"types\\\":[\\\"child\\\",\\\"same_page\\\",\\\"parent\\\",\\\"ref\\\"],\\\"depth\\\":0},\"\n",
    "\"\\\"topK\\\":40\"\n",
    "\"}\"\n",
    "\"准则：\"\n",
    "\"- 若问题含图/表编号（Figure/Table/图/表 + 序号），用 direct_label 并在 selectors.label/figure_no/table_no 填值。\"\n",
    "\"- 若问题含页码（Page/p./第X页），用 direct_page 并填 selectors.page。\"\n",
    "\"- 含专有名词/缩写/关键短语明显 → sparse；语义问法不明显 → dense；不确定 → hybrid。\"\n",
    "\"- 需要段落/图注级别内容 → need_leaf=true 或 strategy=leaf；只找章节名 → heading。\"\n",
    "\"- expand.depth 建议 0~1，types 默认 [\\\"child\\\",\\\"same_page\\\"]。\"\n",
    "\"仅输出 JSON，不要解释。\"\n",
    ")\n",
    "\n",
    "def validate_policy(obj: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    if not isinstance(obj, dict):\n",
    "        raise ValueError(\"policy must be object\")\n",
    "    strat = obj.get(\"strategy\") or \"hybrid\"\n",
    "    if strat not in ALLOWED_STRATEGY:\n",
    "        strat = \"hybrid\"\n",
    "    roles = obj.get(\"roles\") or [\"section\",\"image\",\"table\"]\n",
    "    roles = [r for r in roles if r in ALLOWED_ROLES] or [\"section\",\"image\",\"table\"]\n",
    "    selectors = obj.get(\"selectors\") or {}\n",
    "    selectors = {\n",
    "        \"label\": str(selectors.get(\"label\") or \"\"),\n",
    "        \"figure_no\": str(selectors.get(\"figure_no\") or \"\"),\n",
    "        \"table_no\": str(selectors.get(\"table_no\") or \"\"),\n",
    "        \"page\": int(selectors.get(\"page\") or 0),\n",
    "    }\n",
    "    queries = obj.get(\"queries\") or {}\n",
    "    queries = {\n",
    "        \"dense\": str(queries.get(\"dense\") or \"\"),\n",
    "        \"sparse\": str(queries.get(\"sparse\") or \"\"),\n",
    "    }\n",
    "    need_leaf = bool(obj.get(\"need_leaf\", False))\n",
    "    expand = obj.get(\"expand\") or {}\n",
    "    types = expand.get(\"types\") or [\"child\",\"same_page\"]\n",
    "    types = [t for t in types if t in ALLOWED_EXPAND] or [\"child\",\"same_page\"]\n",
    "    depth = int(expand.get(\"depth\") or 0)\n",
    "    topK = int(obj.get(\"topK\") or 40)\n",
    "    return {\n",
    "        \"strategy\": strat,\n",
    "        \"roles\": roles,\n",
    "        \"selectors\": selectors,\n",
    "        \"queries\": queries,\n",
    "        \"need_leaf\": need_leaf,\n",
    "        \"expand\": {\"types\": types, \"depth\": max(0, min(2, depth))},\n",
    "        \"topK\": max(1, min(200, topK)),\n",
    "    }\n",
    "\n",
    "def llm_policy(llm_call, question: str) -> Dict[str, Any]:\n",
    "    msgs=[{\"role\":\"system\",\"content\":POLICY_SYS},{\"role\":\"user\",\"content\":question}]\n",
    "    # 你可替换为自己的 JSON 解析器，这里使用已有工具也可\n",
    "    from src.agents.planner import default_llm_json\n",
    "    raw = default_llm_json(msgs, llm_call, max_tokens=240)\n",
    "    return validate_policy(raw or {})\n",
    "\n",
    "def pretty_print_policy(p: Dict[str, Any]) -> None:\n",
    "    print(json.dumps(p, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "544a7e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"strategy\": \"sparse\",\n",
      "  \"roles\": [\n",
      "    \"section\",\n",
      "    \"image\",\n",
      "    \"table\"\n",
      "  ],\n",
      "  \"selectors\": {\n",
      "    \"label\": \"\",\n",
      "    \"figure_no\": \"\",\n",
      "    \"table_no\": \"\",\n",
      "    \"page\": 0\n",
      "  },\n",
      "  \"queries\": {\n",
      "    \"dense\": \"\",\n",
      "    \"sparse\": \"EBITDA Costco FY2021\"\n",
      "  },\n",
      "  \"need_leaf\": false,\n",
      "  \"expand\": {\n",
      "    \"types\": [\n",
      "      \"child\",\n",
      "      \"same_page\"\n",
      "    ],\n",
      "    \"depth\": 1\n",
      "  },\n",
      "  \"topK\": 40\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from src.utils.llm_clients import gpt_llm_call\n",
    "p = llm_policy(\n",
    "          lambda messages, json_mode=True, max_tokens=240, **kw: gpt_llm_call(messages, model=\"gpt-4o-mini\", json_mode=True),\n",
    "          \"what is EBITDA  for costco in FY2021?\",\n",
    "        )\n",
    "pretty_print_policy(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bc86b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8edbfa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单 RRF 融合（后续可替换为你们 planner.py 的 fuse）\n",
    "def _rrf_fuse(dense_cands, sparse_cands, k=60):\n",
    "    rd = {c.node_id:i+1 for i,c in enumerate(dense_cands)}\n",
    "    rs = {c.node_id:i+1 for i,c in enumerate(sparse_cands)}\n",
    "    pool = {}\n",
    "    for c in dense_cands + sparse_cands:\n",
    "        pool.setdefault(c.node_id, c)\n",
    "    fused = []\n",
    "    for nid, c in pool.items():\n",
    "        r1, r2 = rd.get(nid, 10**6), rs.get(nid, 10**6)\n",
    "        score = 1.0/(k+r1) + 1.0/(k+r2)\n",
    "        fused.append((score, c))\n",
    "    fused.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [t[1] for t in fused]\n",
    "\n",
    "def _roles_or_default(roles: List[str] | Set[str] | None) -> Set[str]:\n",
    "    base = {\"section\",\"image\",\"table\"}\n",
    "    if not roles:\n",
    "        return base\n",
    "    r = set(str(x) for x in roles)\n",
    "    return r if r else base\n",
    "\n",
    "def execute_policy(policy: Dict[str, Any], R) -> Dict[str, Any]:\n",
    "    strat = policy.get(\"strategy\") or \"hybrid\"\n",
    "    roles = _roles_or_default(policy.get(\"roles\"))\n",
    "    sel   = policy.get(\"selectors\") or {}\n",
    "    qd    = (policy.get(\"queries\") or {}).get(\"dense\") or \"\"\n",
    "    qs    = (policy.get(\"queries\") or {}).get(\"sparse\") or \"\"\n",
    "    topK  = int(policy.get(\"topK\") or 40)\n",
    "\n",
    "    # 1) 直达类\n",
    "    if strat == \"direct_label\":\n",
    "        label = sel.get(\"label\") or \"\"\n",
    "        # 若没有 label 但给了 figure_no/table_no，组装一下\n",
    "        if not label:\n",
    "            if sel.get(\"figure_no\"): label = f\"Figure {sel['figure_no']}\"\n",
    "            if sel.get(\"table_no\"):  label = f\"Table {sel['table_no']}\"\n",
    "        nid = R.idmap_lookup(label) if label else None\n",
    "        cands = [nid] if nid else []\n",
    "        return {\"mode\": strat, \"candidates\": cands, \"policy\": policy}\n",
    "\n",
    "    if strat == \"direct_page\":\n",
    "        page = int(sel.get(\"page\") or 0)\n",
    "        if page <= 0:\n",
    "            return {\"mode\": strat, \"candidates\": [], \"policy\": policy}\n",
    "        # 直接用 filter_nodes 按页筛选（跨角色）\n",
    "        flt = [{\"field\":\"page_idx\",\"op\":\"=\",\"value\":page}]\n",
    "        out: List[str] = []\n",
    "        if roles:\n",
    "            for r in roles:\n",
    "                out.extend(R.filter_nodes(r, flt))\n",
    "        else:\n",
    "            out = R.filter_nodes(\"\", flt)\n",
    "        # 去重并截断\n",
    "        uniq = list(dict.fromkeys(out))[:topK]\n",
    "        return {\"mode\": strat, \"candidates\": uniq, \"policy\": policy}\n",
    "\n",
    "    # 2) 稀疏/稠密/混合\n",
    "    if strat == \"sparse\":\n",
    "        sp = R.sparse(qs or qd, roles, topK)\n",
    "        return {\"mode\": strat, \"candidates\": [c.node_id for c in sp], \"policy\": policy}\n",
    "\n",
    "    if strat == \"dense\":\n",
    "        de = R.dense(qd or qs, roles, topK)\n",
    "        return {\"mode\": strat, \"candidates\": [c.node_id for c in de], \"policy\": policy}\n",
    "\n",
    "    if strat == \"heading\":\n",
    "        sp = R.sparse((qs or qd) + \" heading title section\", {\"section\"}, topK)\n",
    "        return {\"mode\": strat, \"candidates\": [c.node_id for c in sp], \"policy\": policy}\n",
    "\n",
    "    # 叶子策略：如果索引未包含叶子视图，先退化为混合（roles里包含 paragraph/caption 也不影响）\n",
    "    if strat == \"leaf\":\n",
    "        roles |= {\"paragraph\",\"caption\"}\n",
    "        sp = R.sparse(qs or qd, roles, min(200, topK*5))\n",
    "        de = R.dense(qd or qs, roles, min(200, topK*5))\n",
    "        fu = _rrf_fuse(de, sp)[:topK]\n",
    "        return {\"mode\": strat, \"candidates\": [c.node_id for c in fu], \"policy\": policy}\n",
    "\n",
    "    # 默认 hybrid\n",
    "    sp = R.sparse(qs or qd, roles, min(200, topK*5))\n",
    "    de = R.dense(qd or qs, roles, min(200, topK*5))\n",
    "    fu = _rrf_fuse(de, sp)[:topK]\n",
    "    return {\"mode\": \"hybrid\", \"candidates\": [c.node_id for c in fu], \"policy\": policy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f6089",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/data/<dataset>/<doc_id>/index/dense_coarse.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m INDEX_DIR = \u001b[33m\"\u001b[39m\u001b[33m/path/to/data/<dataset>/<doc_id>/index\u001b[39m\u001b[33m\"\u001b[39m   \u001b[38;5;66;03m# 或者 indexes\u001b[39;00m\n\u001b[32m     19\u001b[39m encode_fn = build_hash_encoder(dim=\u001b[32m384\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m R = \u001b[43mJsonlRetriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINDEX_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/MuDocU/DTAgent/src/agents/retriever_impl.py:167\u001b[39m, in \u001b[36mJsonlRetriever.__init__\u001b[39m\u001b[34m(self, index_dir, encode_fn, field_weights)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Load dense_coarse\u001b[39;00m\n\u001b[32m    166\u001b[39m dense_path = os.path.join(index_dir, \u001b[33m\"\u001b[39m\u001b[33mdense_coarse.jsonl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m \u001b[38;5;28mself\u001b[39m.dense_docs: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] = \u001b[43m_read_jsonl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdense_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dense = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.dense_docs)\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# Pre-encode dense_texts\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/MuDocU/DTAgent/src/agents/retriever_impl.py:23\u001b[39m, in \u001b[36m_read_jsonl\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_jsonl\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) -> List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m     22\u001b[39m     out = []\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     24\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[32m     25\u001b[39m             line = line.strip()\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/path/to/data/<dataset>/<doc_id>/index/dense_coarse.jsonl'"
     ]
    }
   ],
   "source": [
    "from src.agents.retriever_impl import JsonlRetriever\n",
    "import numpy as np\n",
    "import re\n",
    "def build_hash_encoder(dim: int = 384):\n",
    "    tok = re.compile(r\"[A-Za-z0-9%._-]+\")\n",
    "    def encode(texts):\n",
    "        X = np.zeros((len(texts), dim), dtype=np.float32)\n",
    "        for i, s in enumerate(texts):\n",
    "            for w in tok.findall(s or \"\"):\n",
    "                h = hash(w) % dim\n",
    "                X[i, h] += 1.0\n",
    "        # L2 归一化\n",
    "        n = np.linalg.norm(X, axis=1, keepdims=True) + 1e-8\n",
    "        X = X / n\n",
    "        return X.astype(np.float32)\n",
    "    return encode\n",
    "\n",
    "INDEX_DIR = \"./../../../data/users/yiming/dtagent/MinerU_25_MMLB/8e7c4cb542ad160f80fb3d795ada35d8/index\"   # 或者 indexes\n",
    "encode_fn = build_hash_encoder(dim=384)\n",
    "R = JsonlRetriever(INDEX_DIR, encode_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f5bb451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"strategy\": \"sparse\",\n",
      "  \"roles\": [\n",
      "    \"section\",\n",
      "    \"image\",\n",
      "    \"table\"\n",
      "  ],\n",
      "  \"selectors\": {\n",
      "    \"label\": \"\",\n",
      "    \"figure_no\": \"\",\n",
      "    \"table_no\": \"\",\n",
      "    \"page\": 0\n",
      "  },\n",
      "  \"queries\": {\n",
      "    \"dense\": \"\",\n",
      "    \"sparse\": \"EBITDA Costco FY2021\"\n",
      "  },\n",
      "  \"need_leaf\": false,\n",
      "  \"expand\": {\n",
      "    \"types\": [\n",
      "      \"child\",\n",
      "      \"same_page\"\n",
      "    ],\n",
      "    \"depth\": 1\n",
      "  },\n",
      "  \"topK\": 40\n",
      "}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'R' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m p = llm_policy(\n\u001b[32m      2\u001b[39m           \u001b[38;5;28;01mlambda\u001b[39;00m messages, json_mode=\u001b[38;5;28;01mTrue\u001b[39;00m, max_tokens=\u001b[32m240\u001b[39m, **kw: gpt_llm_call(messages, model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, json_mode=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m      3\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mwhat is EBITDA  for costco in FY2021?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m         )\n\u001b[32m      5\u001b[39m pretty_print_policy(p)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m res = execute_policy(p, \u001b[43mR\u001b[49m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(res[\u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m], \u001b[38;5;28mlen\u001b[39m(res[\u001b[33m\"\u001b[39m\u001b[33mcandidates\u001b[39m\u001b[33m\"\u001b[39m]))\n\u001b[32m      9\u001b[39m inspect_candidates(R, res[\u001b[33m\"\u001b[39m\u001b[33mcandidates\u001b[39m\u001b[33m\"\u001b[39m], \u001b[32m5\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'R' is not defined"
     ]
    }
   ],
   "source": [
    "p = llm_policy(\n",
    "          lambda messages, json_mode=True, max_tokens=240, **kw: gpt_llm_call(messages, model=\"gpt-4o-mini\", json_mode=True),\n",
    "          \"what is EBITDA  for costco in FY2021?\",\n",
    "        )\n",
    "pretty_print_policy(p)\n",
    "\n",
    "res = execute_policy(p, R)\n",
    "print(res[\"mode\"], len(res[\"candidates\"]))\n",
    "inspect_candidates(R, res[\"candidates\"], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee445a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
